{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "938e1fdc-0199-47ce-82f5-d3ab45630493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb23bc7f-71b5-47c9-bc62-83d33e3f12fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\UGBOKE GEORGE\\Downloads\\NationalNames\\N_gram-name-prediction\\NationalNames.csv', encoding= 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "602e0c19-1c80-4d57-adeb-199ee782793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_names = df['Name'].head(50000)\n",
    "\n",
    "processed_names = [\"^\" + name + \"$\" for name in top_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "661131e6-5664-4c4c-b8e6-945c98c1e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameDataset(Dataset):\n",
    "    def __init__(self, names, n=5):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        chars = set(\"\".join(names))\n",
    "        self.char_to_int = {char: i for i, char in enumerate(chars, start=1)}\n",
    "        self.int_to_char = {i: char for char, i in self.char_to_int.items()}\n",
    "        self.char_to_int[\"<PAD>\"] = 0  # Padding\n",
    "        self.int_to_char[0] = \"<PAD>\"\n",
    "        self.vocab_size = len(self.char_to_int)\n",
    "        \n",
    "        self.samples = []\n",
    "        for name in names:\n",
    "            encoded = [self.char_to_int[c] for c in name]\n",
    "            for i in range(len(encoded) - n):\n",
    "                self.samples.append((encoded[i:i+n], encoded[i+1:i+n+1]))\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.samples[idx]\n",
    "        x_pad = x + [0] * (self.n - len(x))\n",
    "        y_pad = y + [0] * (self.n - len(y))\n",
    "        return torch.tensor(x_pad, dtype=torch.long), torch.tensor(y_pad, dtype=torch.long)\n",
    "\n",
    "# Create the dataset\n",
    "dataset = NameDataset(processed_names, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35b1faa3-cad4-4194-ad27-da18c7f9bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NameGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=64, hidden_dim=128):\n",
    "        super(NameGenerator, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        out = self.fc(lstm_out)\n",
    "        return out\n",
    "\n",
    "model = NameGenerator(dataset.vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a319aff-dd25-4d04-8d2f-9f52c81f1016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.9057051971484797\n",
      "Epoch 2, Loss: 1.5308436500074718\n",
      "Epoch 3, Loss: 1.4093202874694073\n",
      "Epoch 4, Loss: 1.351604914161521\n",
      "Epoch 5, Loss: 1.3202195391968383\n",
      "Epoch 6, Loss: 1.3010358233966737\n",
      "Epoch 7, Loss: 1.2879191190983768\n",
      "Epoch 8, Loss: 1.2781892491618232\n",
      "Epoch 9, Loss: 1.2707445428964677\n",
      "Epoch 10, Loss: 1.264825610095906\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def train_model(model, dataset, batch_size=64, epochs=10):\n",
    "    model.train()\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = Adam(model.parameters())\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for x, y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x)\n",
    "            loss = cross_entropy(pred.transpose(1, 2), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}\")\n",
    "\n",
    "# Training the model\n",
    "train_model(model, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a9843c8-96af-4f13-a6da-142bf52ab4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salome\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def predict_name(model, dataset, start_char='^', max_length=20):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The trained PyTorch model.\n",
    "    - dataset: The dataset object containing char_to_int and int_to_char mappings.\n",
    "    - start_char: The starting character. Default is '^'.\n",
    "    - max_length: The maximum length of the name to generate.\n",
    "   \n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        chars = [start_char]\n",
    "        for _ in range(max_length):\n",
    "            # Convert current sequence of characters to integers\n",
    "            input_seq = [dataset.char_to_int[c] for c in chars]\n",
    "            # Pad input \n",
    "            input_tensor = torch.tensor([input_seq], dtype=torch.long)\n",
    "            # Get predictions\n",
    "            output = model(input_tensor)\n",
    "            # Convert output probabilities to next character\n",
    "            probabilities = torch.softmax(output[0, -1], dim=0).numpy()\n",
    "            next_char_int = np.random.choice(len(probabilities), p=probabilities)\n",
    "            next_char = dataset.int_to_char[next_char_int]\n",
    "            if next_char == '$':  # End of sequence\n",
    "                break\n",
    "            chars.append(next_char)\n",
    "        return ''.join(chars[1:])  # Skip the start-of-sequence character in the output\n",
    "\n",
    "# Example usage\n",
    "generated_name = predict_name(model, dataset)\n",
    "print(generated_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
